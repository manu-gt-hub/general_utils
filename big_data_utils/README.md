# big_data_utils

# Big Data Utilities

This repository contains a collection of scripts and notebooks with utilities for working with Big Data, focused on the Apache Spark ecosystem, Databricks, and cloud storage (S3, Azure Blob, etc.).

---

## Contents

- Scripts to read and process data in CSV, Parquet, JSON formats.
- Examples of configuration for accessing S3 from Spark.
- Utilities for managing mountpoints in Databricks.
- Sample code for API integration and task automation.

---

## Disclaimer

> ⚠️ **This repository is for educational and learning purposes only.**  
> There is no guarantee that the code is production-ready or secure for use in production environments.  
> Use these resources at your own risk and always validate and adapt the code according to your needs and security standards.
